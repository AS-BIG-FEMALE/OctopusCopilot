# This is the number of items you can place in the context of a question before the LLM starts to
# generate incorrect responses. It is mostly based on the observations from the experiment in
# dynamic_deployment_experiments_4d.py.
max_context = 20
